---
title: "R Tips"
author: "J. R. Minter"
date: "Started: 2013-07-16, Last modified: 2020-04-10"
output:
  html_document:
    css: ../theme/jm-gray-vignette.css
    number_sections: yes
    toc: yes
    toc_depth: 3
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
library(knitr)
options(width = 72)

suppressPackageStartupMessages(library("tidyverse"))
```


[Back to Index](../README.html)

# Don't forget...

## Conflict between `here::here()` and `lubridate`

There is an annoying conflict between `here::here()` and `lubridate`.

```{r testHH, echo=TRUE, message=FALSE}
library(here)
library(lubridate)

pa <- paste0(here::here(), "/my/path/to_csv")
pa

da <- lubridate::ymd(20200410)
da

now("GMT")

now("")

now() == now() # would be TRUE if computer processed both at the same instant

now() < now() # TRUE

now() > now() # FALSE

```


## Differences in R-3.6.0

- Changes in the serializarion format: From
[David Smith](https://blog.revolutionanalytics.com/2019/05/whats-new-in-r-360.html)

> Changes to R's serialization format. If you want to save R data to disk with
> `R 3.6.0` and read it back with R version 3.4.4 or earlier, you'll need to use
> `readRDS("mydata.Rd",version=2)` to save your data in the old serialization
> format, which has been updated to Version 3 for this release. (The same
> applies to the functions `save`, `serialize`, and byte-compiled R code.)
> The R 3.5 series had forwards-compatibility in mind, and can already read
> data serialized in the Version 3 format.

## Remove R-Studio

Sometimes we need a clean install...


From [RStudio](https://support.rstudio.com/hc/en-us/articles/200554736-How-To-Uninstall-RStudio-Desktop)

Uninstalling RStudio Desktop is the same as a typical application on your
system.


### Windows

Run the program uninstaller from the Start Menu
`(All Programs | RStudio | Uninstall)`. Alternatively, you may use the
`Add or Remove Programs` utility from the control panel.

### Mac

Simply drag the RStudio application into the trash from your
Applications directory.

### Linux

Remove RStudio using your system's uninstaller from the command line:

- **Debian/Ubuntu** - `$ sudo apt-get remove rstudio`
- **CentOS/RedHat/Fedora** - `$ sudo rpm -e rstudio`

## Saved Settings and Preferences

After uninstalling RStudio, your personalized settings are preserved in
the RStudio-Desktop directory. This remains on your system in case you
decide to reinstall RStudio. If you wish to delete this hidden directory,
it is stored in the following locations:

- **Windows 7**: The user's local App Data directory
`%AppData%\RStudio`

- **Windows XP**: The user's local App Data directory
`Local Settings\Application Data`

- **Mac OS**: The user's home directory `~/.rstudio-desktop`

- **Linux**: The user's home directory `~/.rstudio-desktop`


## pdftools

See [Jeroen Ooms](https://ropensci.org/technotes/2019/04/24/pdftools-22/)
tutorial on the latest (2019-04-24) `pdftools` package

### Split and Join PDF files

It is now possible to split, join, and compress pdf files with pdftools.
For example the `pdf_subset()` function creates a new pdf file with a
selection of the pages from the input file:

```
# Load pdftools
library(pdftools)

# extract some pages
pdf_subset('https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf',
  pages = 1:3, output = "subset.pdf")

# Should say 3
pdf_length("subset.pdf")
```

Similarly `pdf_combine()` is used to join several pdf files into one.

```
# Generate another pdf
pdf("test.pdf")
plot(mtcars)
dev.off()

# Combine them with the other one
pdf_combine(c("test.pdf", "subset.pdf"), output = "joined.pdf")

# Should say 4
pdf_length("joined.pdf")
```

The split and join features are provided via a new package `qpdf` which
wraps the `qpdf` C++ library. The main benefit of `qpdf` is that no external
software (such as pdftk) is needed. The `qpdf` package is entirely self
contained and works reliably on all operating systems with zero system
dependencies.

Data extraction now available on Linux too

The pdftools 2.0 announcement post from December introduced the new
`pdf_data()` function for extracting individual text boxes from pdf
files. However it was noted that this function was not yet available
on most Linux distributions because it requires a recent fix from
`poppler 0.73`. I am happy to say that this should soon work on all
major Linux distributions. Ubuntu has upgraded to `poppler 0.74` on
Ubuntu Disco which was released this week. I also created a PPA for
`Ubuntu 16.04` (Xenial) and `18.04` (Bionic) with backports of poppler
0.74. This makes it possible to use pdf_data on Ubuntu LTS servers,
including Travis:

```
sudo add-apt-repository ppa:cran/poppler
sudo apt-get update
sudo apt-get install libpoppler-cpp-dev
```

Moreover, the upcoming Fedora 30 will ship with poppler-devel 0.73.
Finally, the upcoming Debian â€œBusterâ€ release will ship with
`poppler 0.71`, but the Debian maintainers were nice enough to let
me backport the required patch from poppler 0.73, so `pdf_data()`
will work on Debian (and hence CRAN) as well!

## Keybord short cuts. Use CMD for Mac, CTL for PC..

- CMD+Shift+M gives `%>%` (the pipe operator)

- alt + "-" in RStudio for `<-` (assignment operator)

## Edit the .Renviron file in RStudio

This is awesome... Edit the `.Renvion` file from RStudio!

From [Cderv](https://community.rstudio.com/t/how-to-set-a-variable-in-renviron/5029/4)

- `usethis::edit_r_environ()` edits the global file

- `usethis::edit_r_environ("project")` will open the one in your project

He suggests learning about how R's
[startup](https://rviews.rstudio.com/2017/04/19/r-for-enterprise-understanding-r-s-startup/)
works...

The link has this helpful graphic

![The R Startup in a nutshell](./inc/R_Startup.jpg)

## For mac rstats folks...

From [Bob Rudis](https://twitter.com/hrbrmstr/status/1111046690872705025)
Periodically run...

```
brew update && brew upgrade && brew cleanup
```

and consider updating your ðŸ“¦/modules/et. al. that depend on any libraries
from them.

## Issues with building R packages

1. Download and install the command line tools from
[developer.apple.com](https://developer.apple.com/download/more/)

2. Install the macOS SDK headers 

    From a comment by clason [here](https://github.com/neovim/neovim/issues/9050).

    > Starting with Mojave, the headers are no longer installed under
    > `/usr/include/` by default -- look under `Command Line Tools -> New Features`
    > in the release notes.
    >
    > Running:
    >
    >```
    > open /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg
    >```
    > from the command line fixes the issue (at least for me and using `brew`).
    > 
    > The release notes also states that this compatibility package will no longer
    > be provided in the near future, so the build system on macOS will have to be
    > adapted to look for headers in the SDK, making this (at that future point)
    > indeed an nvim issue (if you do not want to punt this to homebrew). @jamessan


## fs::dir_tree()

Show the directory tree. Great for R project directories...

```
fs::dir_tree(here::here())
```

Consider this approach to view a project directory.

From the project directory, type this:

```
> sink(file="~/Desktop/proj_name.txt")
> fs::dir_tree(".")
> sink()
```

## Code download in Rmarkdown HTML file

Hat Tip [Alison Hill](https://twitter.com/apreshill/status/1108925218850893832)

Use YAML like this

```
---
output:
  html_document:
    code_download: true
---
```

She provides an example
[here](https://elastic-lovelace-155848.netlify.com/gallery/themes/flatly.html).

The user may download the `.Rmd` file. Very helpful for reproducible
analyses.

## Combining csv files into one dataframe

From [Patrick Stoltz](https://twitter.com/PatrickStotz/status/1107964762305036293)
on Twitter... The idea originated
[here](https://serialmentor.com/blog/2016/6/13/reading-and-combining-many-tidy-data-files-in-R).

```
# find all file names ending in .csv 
files = dir(pattern = "*.csv")

# read and reduce to one dataframe
data = files %>%
       map(read_csv) %>%
       reduce(rbind)
```


## Fixing pandoc access error on Windows

Kevin Ushey sent me a script to replace the RStudio pandoc with
pandoc 2.7.1 built with ghc-8.6.4. It worked great on my Win7 x64
box and on my Win 10 parallels VM. On the Win 10 box, I need to run
RStudio as an Administrator.

**Note**: Yihui Xie shows how to get the pandoc version:

```{r get-pandoc-version, echo=TRUE}
rmarkdown::pandoc_version()
```
Currently running with pandoc32 on My win7 box and my Win10 64 VM on Mac


## RStudio crashes on opening project

Seems to help to delete the `.Rproj.user` folder before opening. RStudio
creates a new one as needed...

This is tracked in RStudio's [github](https://github.com/rstudio/rstudio/issues/4034)
repository. Kevin Ushey wrote me and suggested I **uncheck** two boxes in the
`Advanced General` pane.

![Solution suggested by Kevin Ushey](inc/Fix-Rstudio-Crash.png)

## Issue with `-fopenmp`

See [nsaunders.wordpress.com](https://nsaunders.wordpress.com/2018/11/19/using-osx-compiling-an-r-package-from-source-issues-with-fopenmp-try-this/)

If you see an error like this

```
clang: error: unsupported option '-fopenmp'
make: *** [external_metis.o] Error 1
ERROR: compilation failed for package â€˜TMBâ€™
```
And you use Homebrew â€“ first, do this:

```
brew install llvm
```

Then create the file `~/.R/Makevars`, if it does not exist and edit its
contents to look like this:

```
C=/usr/local/opt/llvm/bin/clang
CXX=/usr/local/opt/llvm/bin/clang++
```

Your R package should now compile without error. If it works as it
did for me :)


## Pandoc on macosx

The current version of R works besr with `pandoc-2.2.1`. I had that
installed with miniconda but had some path issues. I created a copy in
`$HOME/bin` and put it first in the path in the `.Renviron` file. I have
scripts to copy to/from Dropbox.

## Some great entries for the setup chunk

Add these to the `{r setup, include=FALSE}` chunk.
I learned this from an example by [drsimonj](https://github.com/drsimonj/tidyverse_tutorial-useR2018)
from the 2018 UseR tutorial on the `tidyverse`.

```
knitr::opts_chunk$set(echo=TRUE,
  comment = NA,
  fig.align = "centre",
  fig.height = 4,
  message = FALSE,
  warning = FALSE,
  error = FALSE)

```

## Key RStudio list files

RStudio keeps some very helpful lists. These are in the directory

```
$HOME/.rstudio-desktop/monitored/lists
```

on macOS and in 

```
%HOME%\AppData\Local\RStudio-Desktop\monitored\lists
```
on Windows(7).  These are **plain text files** and are easily edited.

- **project_mru**: text file with links to projects
- **file_mru**: list of recent files
- **help_history_links**: list of help queries
- **user_dictionary**:  list of terms not to flag in spell checker.

## The pipe operator

See the examples [here](../R-data-pipeline/R-data-pipeline.html).

## Key RStudio Project Settings

Tabs and spaces can be a **big** problem. The **tidyverse** and similar
projects use spaces for tabs and a 2 space equivalent. Below are my
current favorite project settings:

```
Version: 1.0

RestoreWorkspace: No
SaveWorkspace: No
AlwaysSaveHistory: Yes

EnableCodeIndexing: Yes
UseSpacesForTab: Yes
NumSpacesForTab: 2
Encoding: UTF-8

RnwWeave: knitr
LaTeX: XeLaTeX

BuildType: Package
PackageUseDevtools: Yes
PackageInstallArgs: --no-multiarch --with-keep.source
```

## Stop printing hashes

Use a chunk like this

```
{r cars, comment=NA, echo = TRUE}
summary(cars)
```

To not print hashes

```{r cars, comment=NA, echo = TRUE}
summary(cars)
```

## Easier Rounding

The brute force approach...

```{r bruteForce, comment=NA}
paste0(round(0.20394 * 100, 1), '%')
```

Use the `scales` package

```{r rounding, comment=NA}
library(scales)
percent(0.20394)
```

## Controlling images size in RMarkdown documents

Use a chunk like this

```
{r showImg,fig.width=7.5,echo=FALSE}

library(png)
library(grid)
manySampImg <- readPNG('inc/many-samples.png')
grid.raster(manySampImg)

```
That produces output like this

```{r showImg,fig.width=7.5,echo=FALSE}
library(png)
library(grid)
manySampImg <- readPNG('inc/many-samples.png')
grid.raster(manySampImg)
```

## Building R on Ubuntu 16.04

See [building from source](https://support.rstudio.com/hc/en-us/articles/218004217-Building-R-from-source)
and [changing versions](https://support.rstudio.com/hc/en-us/articles/200486138-Changing-R-versions-for-RStudio-desktop).

1. Need to enable source packages (edit  `/etc/apt/sources.list`). Then
run `sudo apt-get update`.

2. Install build dependencies. Run `sudo apt-get build-dep r-base`.

3. Build R

```
./configure --prefix=/home/jrminter/apps/R/3.5.1/ --enable-R-shlib --with-blas --with-lapack
make
make install
```

4. Make available to RStudio

From [here](https://askubuntu.com/questions/261760/setting-global-environment-variable-for-everyone)

In `.bashrc`

```
export RSTUDIO_WHICH_R="/home/jrminter/apps/R/3.5.1/bin/R"
```

In `/etc/environment` to make it system wide... I found I 
needed to set the TEMP environment too...

```
RSTUDIO_WHICH_R="/home/jrminter/apps/R/3.5.1/bin/R"
TEMP="/home/jrminter/tmp"
```

# Some hints on key packages

## From [Steph Locke](https://twitter.com/SteffLocke/status/990251709531344896)

My #rstats #datascience goto packages:

**IO**: odbc readxl httr    
**EDA**: DataExplorer    
**Prep**: tidyverse     
**Sampling**: rsample modelr    
**Feature Engineering**: recipes    
**Modelling**: glmnet h2o FFTrees    
**Evaluation**: broom yardstick    
**Deployment**: sqlrutils AzureML opencpu    
**Monitoring**: flexdashboard    
**Docs**: rmarkdown    

## Supress startup messages

I **really** like this one:

```{r supress.startup.messages}
suppressPackageStartupMessages(library("tidyverse"))
```

Might as well read the rest of the post that gave the idea and
learn the value of
[quasi-quotation](http://blog.jalsalam.com/posts/2017/quasi-quotation-applications/)
with the **tidyverse**.

## YAML for vignettes with numbered sections and a TOC

```
---
title: "The catchy title"
author: "John Minter"
date: "Started: 2018-05-01, Last updated: 2018-05-29"
output:
  rmarkdown::html_vignette:
    number_sections: true
    toc: true
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{The catchy title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```

## Get key version information

```{r get.r.version}
R.version.string
```

```{r get.r.markdown.version}
packageVersion("rmarkdown")
```

Note that this will work from the command line in RStudio but not with knitr:

```
library(rstudioapi)
versionInfo()
```

## Get the .gitignore right...

[This](https://stackoverflow.com/questions/36185456/gitignored-files-still-shown-in-rstudio)
post on StackOverflow was **very** helpful. We want to ignore all the
files in `.Rproj.user` and the directories below. here is how you fix:

1. Remove what was previously committed

```
git rm -r --cached .Rproj.user/**
git commit -m "Removed files...."
```

2. Now add the right entry to **.gitignore**. Note the two asterics...

```
.Rproj.user/**
```

## Special symbols...

1. Use `demo(plotmath)` to see syntax for mathematical expressions.

2. Also look at `latex2exp` on [github](https://github.com/stefano-meschiari/latex2exp).

3. Use `bquote()`. Here are some tips based on a blog post
by [Tyler Rinker](https://trinkerrstuff.wordpress.com/2018/03/15/2246/)

- **Math notations require an expression or call**
See [Advanced R](http://adv-r.had.co.nz/Expressions.html) for details.
This [Stackoverflow](https://stackoverflow.com/questions/20355547/expression-vs-call)
question explains the difference between the two.

- **Use bquote:**  
**Strings**: Require quotes wrapped w/ tilde separator (e.g., "my text"  ~).  
**Math Expressions**: Unquoted & follow `?plotmath`.  
**Numbers**: Unquoted when part of math notation.  
**Variables**: Use `.()` (pass in string or numeric).

- An example using base graphics

```{r, bquoteBaseGraphics}
## A variable to pass in
cor <- -.321
cor2 <- '-.321'
 
par(mfrow = c(1, 2))
plot(1:10, 1:10, main = bquote("Hello" ~ r[xy] == .(cor) ~ "and" ~ B^2))
plot(1:10, 1:10, main = bquote("Hello" ~ r[xy] == .(cor2) ~ "and" ~ B^2))
```


- An example with `ggplot()` using Greek as well (suggested by
Julia Silge)

```{r, bquoteGGplot}
library(ggplot2)
cor2 <- '-.321'

df <- data.frame(x=1:10, y=1:10) 
plt <- ggplot() +
       geom_point(data=df, aes(x=x, y=y),  colour="darkblue") +
       scale_x_continuous(breaks = seq(from = 0, to = 10, by = 2),
                          limits = c(0, 10)) +
       scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2),
                          limits = c(0, 10)) +
       xlab("x") +
       ylab("y") +
       ggtitle(bquote("Eq 1:" ~ y[i] == alpha + beta * x[i] + epsilon[i] ~ "or" ~ .(cor2))) +
       theme(axis.text=element_text(size=12),
       axis.title=element_text(size=12),
       plot.title=element_text(hjust = 0.5))

print(plt)
```


## To start Rserve

```
library(Rserve)
Rserve(args="--no-save")
```

## Get rJava packages to work

Use a call like this to unset `JAVA_HOME` so that the values in 
`R-3.4.x\etc\x64\Makeconf` and <br> 
`R-3.4.x\etc\i386\Makeconf`
are used:

```
if( Sys.info()['sysname'] == "Windows"){
	
	Sys.setenv(JAVA_HOME="")
	print("unset JAVA_HOME for Windows")
}

```

I had a terrible time getting `rcdk` to install....

I added this to `Rprofile.site` in 

```
C:\Apps\R\R-3.4.3\etc
```

## Vignettes

### To force building

#### Build locally

```
devtools::install(pkg = ".", build_vignettes = TRUE)
```
This builds and installs a binary package.

#### Build from github

```
devtools::install_github('jrminter/statshelpR',build_vignettes=TRUE)
```

### To browse
```
browseVignettes(package = NULL, lib.loc = NULL, all = TRUE)
e.g.
browseVignettes(package="statshelpR")

```

## Set the path in .Renviron on MacOSX

I needed this:

```
# Python 3.6
PATH=/Users/jrminter/miniconda3/bin:/Library/TeX/texbin:/usr/local/bin:/Users/jrminter/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin
LATEX=/usr/local/texlive/2017/bin/x86_64-darwin/pdflatex
WORK=/Users/jrminter/Documents/work
```

## Avoid rJava woes

Under windows, rJava needs to have **jvm.dll** in the path. On
my systems, it is best to add
**C:\\Apps\\Java64\\jre8\\bin\\server** to the path...

## Key R-Markdown resources

[R Notebooks](http://rmarkdown.rstudio.com/r_notebooks.html)

[Beamer presentations](http://rmarkdown.rstudio.com/beamer_presentation_format.html#overview)

[R Markdown v.2 home](http://rmarkdown.rstudio.com/index.html)

[Presentations in R Markdown with reveal.js](http://rmarkdown.rstudio.com/revealjs_presentation_format.html)

A cool tip from [A. Jonathan R. Godfrey](https://r-resources.massey.ac.nz/rmarkdown/):

> Get rid of those hash/number signs on the R output by using `comment=""` for all chunks that generate output.

For example, add it to the opening chunk

```
library(knitr)
opts_chunk$set(comment="")
```

## Changing dataframe column class

```
class(df$col) = "integer"
```

## How to use extra fonts

From the **Revolution Analytics** [blog](http://blog.revolutionanalytics.com/2012/09/how-to-use-your-favorite-fonts-in-r-charts.html)


1. Install the **extrafont** package

```
install.packages("extrafont")
```

2. Import the fonts into your system. This takes a few minutes... It loads the system fonts into extrafont's database

```
library(extrafont)
font_import()
```

3. See what fonts we have. I like **Open Sans Semibold**

```
fonts()
```

4. Get more detailed info

```
fonttable()
```

5. Create a PDF with fonts

```
cairo_pdf("plot-open-sans.pdf", family="Open Sans Semibold", width=9.0, height=6.0)

plot(mtcars$mpg, mtcars$wt, 
     main = "Fuel Efficiency of 32 Cars",
     xlab = "Weight (x1000 lb)",
     ylab = "Miles per Gallon")

dev.off()
```


or with **ggplot2**


```
library(extrafont)
loadfonts()
library(ggplot2)
p <- ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point() +
     ggtitle("Fuel Efficiency of 32 Cars") +
     xlab("Weight (x1000 lb)") + ylab("Miles per Gallon") +
     theme_bw() +
     theme(text=element_text(family="Open Sans Extrabold", size=14))

ggsave("ggplot-open-sans-eb.pdf", p, width=9.0, height=6.0)

p <- ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point() +
     ggtitle("Fuel Efficiency of 32 Cars") +
     xlab("Weight (x1000 lb)") + ylab("Miles per Gallon") +
     theme_bw() +
     theme(text=element_text(family="Open Sans Semibold", size=14))

ggsave("ggplot-open-sans-sb.pdf", p, width=9.0, height=6.0)
```

6. Embed the fonts in the PDF with **ghostscript**

```
Sys.setenv(R_GSCMD = "C:/Apps/gs/gs9.20/bin/gswin64c.exe")
embed_fonts("ggplot-open-sans-sb.pdf", outfile="ggplot-open-sans-sb-embed.pdf")
embed_fonts("ggplot-open-sans-eb.pdf", outfile="ggplot-open-sans-eb-embed.pdf")
```


## Other

[datascienceriot](https://www.datascienceriot.com/how-to-install-r-in-linux-ubuntu-16-04-xenial-xerus/kris/) shows how to install R and R-Studion on Ubuntu 16.04 Xenial Xerus.

RStudio - Tomorrow Night Bright theme is easy on the eyes. Monokai is
somewhat better.

[rud.is](http://rud.is/b/2015/10/20/installing-r-on-os-x/) has a nice
guide to installation on Mac OSX.

[Google](http://google-styleguide.googlecode.com/svn/trunk/Rguide.xml)
has a nice R style guide.

R can be **really** frustrating at time. These are some
tips on matters that made me go *hmmm...*

# Adjustments for El Capitan

1. **Make changes to .Renviron** . This makes sure R (esp. RStudio) can
find what it needs. Mine is:

```
PATH= /Library/TeX/texbin:/usr/local/bin:/Users/jrminter/scripts:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin
LATEX=/usr/local/texlive/2015/bin/x86_64-darwin/pdflatex
```
2. **Make changes to .profile** This makes sure we can run make. Path
is key. Mine uses environment variables and includes:

```
export PATH=/Library/TeX/texbin:/Library/Frameworks/R.framework/Versions/3.2/Resources/bin:/usr/local/bin:~/scripts:$PATH
export EDITOR="subl -n -w"
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home
GIT_HOME=~/git
IMG_ROOT=~/dat/images
EDS_ROOT=~/dat/eds
export GIT_HOME
export IMG_ROOT
export EDS_ROOT
alias instR="R CMD INSTALL *.gz; rm -rf *.gz"
```


# Cool R-markdown Examples

[JoÃ£o Neto](http://www.di.fc.ul.pt/~jpn/r/) has some really nice
examples. They plot as `.html` but one can change the extension to
`.Rmd` to get the source.

# Speeding up compile on 64 bit R

From [here](http://www.rexamine.com/2015/07/speeding-up-r-package-installation-process/)

On many R installations, the build process is set up so that only one
C/C++ source file is compiled at a time. Yet, there is a simple solution
for that â€” we may ask GNU make to allow more than one job to be submitted
at once. In order to do so, we edit the `/lib64/R/etc/Renviron` file
(where `/lib64/R/etc/`) is the result to a call to the R.home() function
in R) and set:

```
MAKE='make -j 8' # submit 8 jobs at once
```
instead of previously used settings. This significantly decreases the
time needed to compile.

# Configuring local soft on Windows.

HT [stewid](https://github.com/ropensci/git2r/issues/139#issuecomment-101176755)

See [this](http://www.stats.ox.ac.uk/pub/Rtools/libs.html) for how
to configure `LOCAL_SOFT`.

I created `C:/Apps/R/local/local320` and unzipped `local320.zip` and
`spatial320.zip` there and set `LOCAL_SOFT` in `etc/{i386,x64}/Makeconf`
(line 30) files in the binary distribution. This means I could add other
versions accordingly.


# Using Hmisc LaTeX functions without Miktex

TexLive does not include the expected Windows dvi viewer `yap` which
is standard with Miktex and is expected on Windows with Hmisc. The
workaround is to use the `option` command. Try this solution that will
write a tex file in the `$TEMP` directory. *Note:* one must manuall
close the `dviout` window for the script to continue.

```{r, message=FALSE}
library(Hmisc)
wd <- getwd()
tmp <- Sys.getenv("TEMP")
if(tmp==""){
  tmp ="/home/jrminter/tmp"
}
setwd(tmp)
x <- matrix(1:6, nrow=2,
            dimnames=list(c('a','b'),c('c','d','this that')))

if(Sys.info()['sysname'] == "Windows"){
  options(xdvicmd='dviout.exe')
}
# This will display the file (and work...)
#
# latex(x, file='matrix.tex')
#
# we can supress display by specifying the file and storing the
# result in an object...
ignore <- latex(x, file='matrix.tex')
setwd(wd)
```

# Upgrade packages after new version

```
update.packages(checkBuilt=TRUE, ask=FALSE)
```

# Some hints from Karl Broman for mac

from [Stack Overflow](https://github.com/kbroman/ProgrammingNotes)

## installing gfortran

```
cd ~/Desktop
wget http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2
sudo tar fxz ~/Desktop/gfortran-4.8.2-darwin13.tar.bz2 -C /
```

Place in `~/.R/config`:

```
CC=clang
CXX=clang++
F77=gfortran-4.8
FC=$F77
OBJC=clang
```

Also, place in `~/.R/Makevars`:

```
CFLAGS=-g -O2 -Wall -pedantic
CXXFLAGS=-g -O2 -Wall -pedantic
```

# Crash when using knitr

Make certain that

```{r}
library(knitr)
```

is in the first chunk calling R


# Tables from knitr and Rmarkdown in RStudio

The `pander` packages seems to work

```
n <- 100
x <- rnorm(n)
y <- 2*x + rnorm(n)
out <- lm(y ~ x)
library(pander)
# panderOptions("digits", 2)
pander(out)
```
as does this

```
df <- cars[1:4,]
pander(df)
```

# Using custom environment variables
Custom environment variables are helpful in standardizing relative
paths across systems. On Linux and MacOSX (using bash,)
I set these in ``.profile``

```
GIT_HOME=~/git
IMG_ROOT=~/dat/images
export GIT_HOME
export IMG_ROOT
```
In Windows, I set these as user environment variables.
Note that in Windows, I set one more like:

```
GITHOME C:\Users\jrminter\git
```
And on win32, I change

```
TEMP c:\Temp\tmp
```
Because the usual ``Documents and Settings\\username\\...`` path gets
too long for building some R packages (like tikzDevice).

Note the windows path format (I hate backslashes.)
What were you thinking, Bill Gates??? BTW - what is wrong with short
path names like usr, bin, tmp ???

This lets me use a command file
to
```
cd %GITHOME%
```

This was useful in the command file
``__install-all-jrm-r-pkgs.cmd`` that I use to
install the latest version of my R-packages
from my git repository.

Running R from the terminal picks these up, but in Linux and MacOSX,
RStudio doesn't (not sure why it does on Windows). The work-around
is to use the r-environment file. 

On Linux, the site r-environment file is in:
```
$R_HOME/lib/R/etc/Renviron
```
On MacOSX with homebrew, this is in:
```
/Library/Frameworks/R.framework/Resources/etc/Renviron
```
This is a good place to set environment variables...

Then in R, one gets

```{r}
print(Sys.getenv("GIT_HOME"))
print(Sys.getenv("GITHOME"))
print(Sys.getenv("IMG_ROOT"))

```
# LaTeX in R Plots

## latexexp

This is from
[here](http://www.magesblog.com/2015/07/adding-mathematical-notations-to-r-plots.html)
and was accessed 2015-07-07.

One needs to remember to escape the `"\"` character, that is write `"\\"`
instead of `"\"`.

```{r, fig.width=7.5, fig.height=7.5}
library(latex2exp)
x <- seq(-4, 4, len = 101)
y <- cbind(sin(x), cos(x))
 
op=par(mfrow=c(2,1))
# plotmath
matplot(x, y, type = "l", xaxt = "n",
        main = expression(paste("plotmath: ", plain(sin) * phi, "  and  ",
                                plain(cos) * phi)),
        ylab = expression("sin" * phi, "cos" * phi), # only 1st is taken
        xlab = expression(paste("Phase Angle ", phi)),
        col.main = "blue")
axis(1, at = c(-pi, -pi/2, 0, pi/2, pi),
     labels = expression(-pi, -pi/2, 0, pi/2, pi))
 
# latex2exp
matplot(x, y, type = "l", xaxt = "n",
        main = latex2exp("latex2exp: $\\sin \\phi$ and $\\cos \\phi$"),
        ylab = latex2exp("$\\sin \\phi$ and $\\cos \\phi$"),
        xlab = latex2exp("Phase Angle $\\phi$"),
        col.main = "blue")
axis(1, at = c(-pi, -pi/2, 0, pi/2, pi),
     labels = sapply(c("$-\\pi$", "$-\\pi/2$", 
                        "0", "$\\pi/2$", "$\\pi$"),
                     latex2exp))
par(op)
```

## TikzDevice

The tikzDevice R package is again being maintained and is back on CRAN.
This permits you to output a plot as a `.tex` file and have full $\LaTeX$
text. Here is an example. First we create the file `normDist.R` to output
the tikzpicture file as `normDist.tex`.

```
library(tikzDevice)

setwd('C:/Temp')

tikz('normDist.tex', width=7, height=7)
# Normal distribution curve
x <- seq(-4.5,4.5,length.out=100)
y <- dnorm(x)

# Integration points
xi <- seq(-2,2,length.out=30)
yi <- dnorm(xi)

# plot the curve
plot(x,y,type='l',lwd=3,col='red',ylab='\\Large{$p(x)$}',xlab='\\Large{$x$}')
# plot the panels
lines(xi,yi,type='s')
lines(range(xi),c(0,0))
lines(xi,yi,type='h')

#Add some equations as labels
title(main="\\LARGE{$p(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}$}")
int <- integrate(dnorm,min(xi),max(xi),subdivisions=length(xi))
text(2.8, 0.3, paste("\\Large{$\\displaystyle\\int_{", min(xi),
                     "}^{", max(xi), "}p(x)dx\\approx", round(int[['value']],3),
                     '$}', sep=''))

#Close the device
dev.off()


# this line lets one input the file...
str.ei <- '\\endinput'
cat(str.ei, file='normDist.tex', sep='\n', append=TRUE)
```

One can then simply include the file in the main $\LaTeX$ file

```
\input{"normDist.tex"}
```

# Using colClasses when reading data into R

[Mollie's Research Blog](http://www.mollietaylor.com/2013/09/using-colclasses-to-load-data-more.html)

Specifying a colClasses argument to read.table or read.csv can save time
on importing data, while also saving steps to specify classes for each
variable later.

```
largeData <- read.csv("huge-file.csv",
                      header = TRUE,
                      colClasses = c("character", "character", "complex",
                      "factor", "factor", "character", "integer", 
                      "integer", "numeric", "character", "character",
                      "Date", "integer", "logical"))
```

# Reading Excel workbooks

[Milano R net](http://www.milanor.net/blog/?p=779)
has a nice description of the available options.

# Colored sizeplot with ggplot2

[martinsbioblogg](http://martinsbioblogg.wordpress.com/2013/11/17/using-r-coloured-sizeplot-with-ggplot2/)

```{r}
library(ggplot2)
library(reshape2)
data <- data.frame(x=c(0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4),
                   y=c(0, 0, 0, 3, 1, 1, 1, 2, 2, 1, 4, 4),
                   group=c(rep(1, 6), rep(2, 4), rep(3, 2)))
counts <- melt(table(data[1:2]))
colnames(counts) <- c(colnames(data)[1:2], "count")
counts <- subset(counts, count != 0)
counts.and.groups <- merge(counts, unique(data))
sizeplot.colour <- qplot(x=x, y=y, size=count, colour=factor(group), data=counts.and.groups) + scale_size(range=c(5, 10))

sizeplot.colour

```

# Least Squares and Maximum Liklihood Calibration
[Ã‰douard Tallent](http://quantcorner.wordpress.com/2013/11/17/least-squares-and-maximum-likelihood-estimation-calibration-with-r/)

```{r}
# Least Squares Calibration
# Please see http://www.sitmo.com/article/calibrating-the-ornstein-uhlenbeck-model/

S <- c(3, 1.76, 1.2693, 1.196, 0.9468,
        0.9532, 0.6252, 0.8604, 1.0984,
        1.431, 1.3019, 1.4005, 1.2686,
        0.7147, 0.9237, 0.7297, 0.7105,
        0.8683, 0.7406, 0.7314, 0.6232)
n <- 20
delta <- 0.25

Sx <- sum(S[1:length(S)-1])
Sy <- sum(S[2:length(S)])
Sxx <- crossprod(S[1:length(S)-1], S[1:length(S)-1])
Sxy <- crossprod(S[1:length(S)-1], S[2:length(S)])
Syy <- crossprod(S[2:length(S)], S[2:length(S)])

a  <- (n*Sxy - Sx * Sy ) / ( n * Sxx - Sx^2 )
b  <- (Sy - a * Sx ) / n
sd <- sqrt((n * Syy - Sy^2 - a * (n * Sxy - Sx * Sy)) / (n * (n-2)))

lambda <- -log(a)/delta
mu <- b/(1-a)
sigma <- sd * sqrt( -2*log(a)/delta/(1-a^2))

res <- c(lambda, mu, sigma)
names(res) <- c("lambda", "mu", "sigma")

res

```


```{r}
# Maximum Likelihood Calibration
# PLease, see http://www.sitmo.com/article/calibrating-the-ornstein-uhlenbeck-model/

S <- c(3, 1.76, 1.2693, 1.196, 0.9468,
        0.9532, 0.6252, 0.8604, 1.0984,
        1.431, 1.3019, 1.4005, 1.2686,
        0.7147, 0.9237, 0.7297, 0.7105,
        0.8683, 0.7406, 0.7314, 0.6232)
n <- 20
delta <- 0.25

Sx <- sum(S[1:length(S)-1])
Sy <- sum(S[2:length(S)])
Sxx <- crossprod(S[1:length(S)-1], S[1:length(S)-1])
Sxy <- crossprod(S[1:length(S)-1], S[2:length(S)])
Syy <- crossprod(S[2:length(S)], S[2:length(S)])

mu  <- (Sy * Sxx - Sx * Sxy) / (n* (Sxx - Sxy) - (Sx^2 - Sx*Sy) )
lambda <- -log((Sxy - mu * Sx - mu * Sy + n * mu^2) /   (Sxx - 2 * mu * Sx + n * mu^2)) / delta
a <- exp(-lambda*delta)
sigmah2 <- (Syy - 2 * a * Sxy + a^2 * Sxx - 2 * mu * (1-a) * (Sy - a * Sx) + n * mu^2 * (1 - a)^2)/n
sigma <- sqrt(sigmah2 * 2 * lambda / (1 - a^2))

res <- c(lambda, mu, sigma)
names(res) <- c("lambda", "mu", "sigma")

res
```


# Mathematical annotation

## Resources
[Vistat Blog](http://vis.supstat.com/2013/04/mathematical-annotation-in-r/)

## Adding results to plot legends and saving to PDF


I like to add values to calibration plots where I have
computed the mean and standard error. Getting the $\pm$
symbol to work on multiple platforms was fun. Note the
``legend`` command.

The other issue is to be able to save a given plot in the
graphics window to a pdf without repeating the plot. The
``dev.copy2pdf`` command comes to the rescue. Note the code
following the plot. The grDevices exemplar warns:

> Note that these functions copy the device region and
> not a plot: the background colour of the device surface
> is part of what is copied. Most screen devices default
> to a transparent background, which is probably not what
> is needed when copying to a device such as png.

```{r, fig.width=4, fig.height=4}
cal.mu <- 5.01
cal.se <- 0.02
cal.un <- "nm/px"
x <- 1:10
y <- 5.01*x
plot(x,y)
abline(a=0,b=cal.mu, col='red')
legend("topleft",legend=bquote("calib:" ~ .(cal.mu) %+-% .(cal.se) ~ .(cal.un)))

str.pdf <-paste0("./figure/foo.pdf")
pdf.options(useDingbats=TRUE)
dev.copy2pdf(file="temp.pdf", width=9,
             height=6, pointsize=12)
# 2019-12-16 - xommented line crashed...
# embedFonts("temp.pdf","pdfwrite", str.pdf)
unlink("temp.pdf")
```
Note that I had odd results with this from R-Studio as
a function of window size. Especially when using Sweave,
I found it helpful to just write a controlled pdf and
from an R script and load/plot from Sweave in the report.

# An example from a R Script
```
my.plot.wrapper <- function(){
  #             B    L    T    R
  std.mar <- c(5.1, 4.1, 4.1, 2.1)
  plt.mar <- c(5.1, 4.1, 0.1, 0.1)
  par(mar=plt.mar)
  x <- 1:10
  y <- 1.5*x+2
  plot(x,y,xlab="X", ylab="Y")
  par(mar=std.mar)
}

# for the graphics window
my.plot.wrapper()

# second time for the pdf
str.pdf <- '../Sweave/inc/foo.pdf'
pdf.options(useDingbats=TRUE)
# note control of w and h and point size
pdf(file="temp.pdf", width=9, height=6, pointsize=14)
my.plot.wrapper()
dev.off()
embedFonts("temp.pdf","pdfwrite", str.pdf)
unlink("temp.pdf")
  
```

Then from LaTeX (e.g. in a beamer template)

```
\begin{frame}{\normalsize{Title}}
  \begin{center}
    \vspace{-0.35in}
    \includegraphics[width=\textwidth]
    {./inc/foo.pdf} \\
    \vspace{0.05in}
  \end{center}
  \vspace{-0.25in}
  \footnotesize{Note how I can control placement better.}
\end{frame}
```

# Tricks with sapply and friends

# A nice example via RBloggers

From [rforwork.info](http://rforwork.info/2013/08/15/sapply-is-my-new-friend/)

There are a couple of cases so far where I've found that sapply really
comes in handy for me:

1. If I want to quickly see some descriptive stats for multiple columns
in my dataframe. For example, the following would show me the medians of
columns 10 through 20, displaying the column names above each median value.

```
sapply(mydf[,10:20], median, na.rm=true)
```



2. If I want to apply the same function to multiple vectors in my
dataframe, modifying them in place. I oftentimes have count variables
that have NA values in place of zeros. I made a "zerofy" function to
add zeros into a vector that lacks them. So, if I want to use my
function to modify these count columns, I can do the following, Which
then replaces the original data in columns 30 through 40 with the
modified data! Handy! 

```
mydf[,30:40] = sapply(mydf[,30:40], zerofy)
```


# Nice examples from Vistat

We can get a good list of symbols with

``demo(plotmath)``

```{r}
par(mar = c(4, 4, 2, 0.1))
plot(rnorm(100), rnorm(100),
  xlab = expression(hat(mu)[0]), ylab = expression(alpha^beta),
  main = expression(paste("Plot of ", alpha^beta, " versus ", hat(mu)[0])))

```

and

```{r}
par(mar = c(4, 4, 2, 0.1))
x_mean <- 1.5
x_sd <- 1.2
hist(rnorm(100, x_mean, x_sd),
  main = substitute(
    paste(X[i], " ~ N(", mu, "=", m, ", ", sigma^2, "=", s2, ")"),
    list(m = x_mean, s2 = x_sd^2)
  )
)

```
# Polygons

From [Daniel Marcelino](http://danielmarcelino.com/advanced-graphics/)

```{r}
# Generate standard normal distribution data for (-5,5)
x = seq(-5,5, length=250)
y = dnorm(x)
# Set up axes with empty plot
plot(x,y, las=1, ylab='dnorm', type='n', yaxs='i', ylim=c(0, 0.5))
# Generate data for the right tail
x2 = seq(qnorm(0.95), 5, length=50)
y2 = dnorm(x2)
# Draw the polygon
polygon(c(x2[1], x2, x2[length(x2)]),  c(0, y2, 0), border=NA, col='grey')
# For the left tail
# but for 2-sided, I think we use alpha/2 and 1-alpha/2
# x3 = seq(-5, qnorm(0.05), length=50)
# y3 = dnorm(x3)
# polygon(c(x3[1], x3, x3[length(x3)]),  c(0, y3, 0), border=NA, col='grey')
lines(x, y)

 
lines(c(2.5, 2.1), c(0.1, 0.02))
text(2.5, 0.115, expression(alpha==0.05))
# For the left tail
# lines(c(-2.5, -2.1), c(0.1, 0.02))
# text(-2.5, 0.115, expression(alpha==-0.05))
# dev.copy(jpeg, 'polygon.jpeg') # save plot as .jpeg
#dev.off()
```

# Drawing 95% Confidence intervals

[Natan Lemoine](http://climateecology.wordpress.com/2013/08/05/drawing-a-95-confidence-interval-in-r/) notes:

I'm writing a post on how to draw a in 95% confidence interval in R by
hand. I spent an hour or so trying to figure this out, and most message
threads point someone to the ellipse() function. However, I wanted to
know how it works.

The basic problem was this. Imagine two random variables with a
bivariate normal distribution, called y, which is an n x 2 matrix with
n rows and 2 columns. The random variables are described by a mean vector
mu and covariance matrix S. The equation for an ellipse is:

$(y â€“ mu) S^1 (y â€“ mu)' = c^2$

The number $c^2$ controls the radius of the ellipse, which we want to
extend to the 95% confidence interval, which is given by a chi-square
distribution with 2 degrees of freedom. The ellipse has two axes, one
for each variable. The axes have half lengths equal to the square-root
of the eigenvalues, with the largest eigenvalue denoting the largest
axis. A further description of this can be found in any multivariat
statistics book (or online).

To calculate the ellipse, we need to do a few things:
1. convert the variables to polar coordinates,
2. extend the new polar variables by the appropriate half lengths (using
eigenvalues),
3. rotate the coordinates based on the variances and covariances, and 
4. move the location of the new coordinates back to the original means.
This will make more sense when we do it by hand.

First, generate some data, plot it, and use the ellipse() function to
make the 95% confidence interval. This is the target interval (I use
it to check myself. If my calculations match, hooray. If not,
I screwed up).


```{r}
library(mvtnorm) # References rmvnorm()
library(ellipse) # References ellipse()
set.seed(17)
 
# Set the covariance matrix
sigma2 <- matrix(c(5, 2, 2, 5), ncol=2)
 
# Set the means
mu <- c(5,5)
 
# Get the correlation matrix
P <- cov2cor(sigma2)
 
# Generate the data
p <- rmvnorm(n=50, mean=mu, sigma=sqrt(sigma2))
 
# Plot the data
plot(p)
 
# Plot the ellipse
lines( ellipse( P, centre = c(5,5)) , col='red')
```

Second, get the eigenvalues and eigenvectors of the correlation matrix.

```{r}
evals <- eigen(P)$values
evecs <- eigen(P)$vectors
```

Third, make a vector of coordinates for a full circle, from 0 to 2*pi
and get the critical value ($c^2$).

```{r}
# Angles of a circle
a <- seq(0, 2*pi, len=100)
 
# Get critical value
c2 <- qchisq(0.95, 2)
c <- sqrt(c2)
```

The vector A above are angles that describe a unit circle. The
coordinates of a unit circle are found by $x = cos(a)$ and $y = sin(a)$
(use trigonometry of a triangle to get this, where the hypotenuse = 1).
We need to extend the unit circle by the appropriate lengths based on
the eigenvalues and then even more by the critical value.

```{r}
# Get the distances
xT <- c * sqrt(evals[1]) * cos(a)
yT <- c * sqrt(evals[2]) * sin(a)
 
M <- cbind(xT, yT)
```

If you plot M, you'll get an ellipse of the appropriate axes lengths,
but centered on 0 and unrotated. Rotate the ellipse using the
eigenvectors, which describe the relationships between the variables
(more appropriately, they give the directions for the vectors of the
major axes of variation). Use the equation u*M' (write this out to see 
this works).

```{r}
# Covert the coordinates
transM <- evecs %*% t(M)
transM <- t(transM)
```

The final step is to move the rotated ellipse back to the original
scale (centered around the original means) and plot the data.

```(r)
lines(transM + mu)
```

This gives the following plot, with the red line being the output from
the ellipse() function.

And that's that! Hopefully this helps someone like me who spent hours
looking but couldn't find anything.



# Confidence levels and intervals in lm fits

This one bit me recently.... Remember that if we want
the $\alpha$ confidence interval, R will report the
values at $(\alpha/2)$ and $(1-\alpha/2)$

Let's do a linear model fit from everybody's favorite
data set, **cars**

```{r}
# do the linear model
fit <- lm(100/mpg ~ disp + hp + wt + am, data=mtcars)
# look at the default 95% confidence intervals
confint(fit, level=0.95)
# and now look at 90% confidence intervals
confint(fit, level=0.90)

```

# Graphics tips

## A nice example from Jeff Leek:

[A useful reference (www.statmethods.net)](http://www.statmethods.net/advgraphs/axes.html)

```{r fig.width=6, fig.height=6}
load('./dat/movies.rda')
# Note the use of jitter on the factor axis...
# and note that the option axes=FALSE suppresses both x and y axes.
# xaxt="n" and yaxt="n" suppress the x and y axis respectively.
plot(movies$score ~ jitter(as.numeric(movies$rating)),
     col="blue",xaxt="n",pch=19)
# note how Jeff labeled the factor variables
axis(side=1,at=unique(as.numeric(movies$rating)),
     labels=unique(movies$rating))
# use of tapply to compute the means
meanRatings <- tapply(movies$score,movies$rating,mean)
points(1:4,meanRatings,col="red",pch="-",cex=5)
```


## Correlation heatmap with ggplot2

from [Martin Johnsson](http://martinsbioblogg.wordpress.com/2013/03/21/using-r-correlation-heatmap-with-ggplot2/)

Just a short post to celebrate that I learned today how incredibly easy
it is to make a heatmap of correlations with ggplot2 (and reshape2, of
course).:

```{r fig.width=7, fig.height=6}
data(attitude)
require(ggplot2)
require(reshape2)
qplot(x=Var1, y=Var2, data=melt(cor(attitude)), fill=value, geom="tile")
```


[Back to Index](../README.html)
